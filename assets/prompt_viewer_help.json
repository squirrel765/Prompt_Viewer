{
  "terms": [
    {
      "name": "Prompt",
      "description": "AI가 이미지를 생성할 때 참고하는 핵심 지시문입니다. 원하는 스타일, 인물, 배경 등을 단어와 문장으로 설명합니다. 예: 'a cat sitting on a chair, realistic, high quality'."
    },
    {
      "name": "Negative Prompt",
      "description": "이미지 생성 시 제외하고 싶은 요소를 지정합니다. 예: 'low quality, blurry, extra fingers' → 품질을 높이고 원하지 않는 결과를 방지."
    },
    {
      "name": "Seed",
      "description": "이미지를 생성할 때 사용되는 무작위 시작값입니다. 같은 Seed와 같은 설정을 쓰면 동일한 이미지를 얻을 수 있고, Seed를 바꾸면 다른 결과가 나옵니다."
    },
    {
      "name": "Sampler",
      "description": "AI가 노이즈를 제거하며 이미지를 만들어가는 방식(알고리즘)입니다. Euler, DDIM, DPM++ 등이 있으며, 샘플러에 따라 결과물의 디테일과 속도가 달라집니다."
    },
    {
      "name": "Steps",
      "description": "이미지 생성 과정에서 노이즈를 제거하는 반복 횟수입니다. Steps가 많을수록 디테일이 좋아질 수 있지만, 너무 많으면 왜곡될 수 있습니다. 보통 20~30 권장."
    },
    {
      "name": "CFG Scale",
      "description": "Classifier-Free Guidance Scale. 프롬프트를 얼마나 강하게 반영할지를 결정합니다. 낮으면 자유로운 결과, 높으면 지시문을 더 충실히 따릅니다. 7~12 정도 권장."
    },
    {
      "name": "Clip Skip",
      "description": "텍스트 인식 모델(CLIP)의 일부 레이어를 건너뛰는 설정입니다. Clip Skip=2는 애니메이션 풍 모델에서 자주 권장됩니다."
    },
    {
      "name": "VAE",
      "description": "Variational Autoencoder. 압축된 데이터에서 색감과 디테일을 복원하는 디코더입니다. VAE를 변경하면 같은 프롬프트라도 색감과 밝기가 달라질 수 있습니다."
    },
    {
      "name": "Checkpoint",
      "description": "모델의 학습 결과 파일(.ckpt, .safetensors). 어떤 데이터셋으로 학습했는지에 따라 화풍이나 표현력이 달라집니다. (예: realistic 모델, anime 모델)"
    },
    {
      "name": "LoRA",
      "description": "Low-Rank Adaptation. 특정 캐릭터, 화풍 등을 추가 학습시킨 경량 모델입니다. 용량이 작고 가중치를 조절해 원하는 정도로 반영할 수 있습니다."
    },
    {
      "name": "Hypernetwork",
      "description": "기존 모델에 연결되는 작은 신경망으로, 특정 스타일이나 분위기를 반영할 수 있습니다. LoRA보다 오래된 방식이지만 특정 상황에서 유용합니다."
    },
    {
      "name": "Embeddings",
      "description": "특정 단어나 개념을 벡터로 학습한 데이터입니다. 프롬프트에 단어를 넣으면 해당 스타일이나 개념이 반영됩니다. (예: 'style_embedding')"
    },
    {
      "name": "Upscaler",
      "description": "생성된 이미지를 확대하거나 화질을 개선하는 알고리즘입니다. ESRGAN, SwinIR 등 다양한 업스케일러가 있습니다."
    },
    {
      "name": "ControlNet",
      "description": "스케치, 포즈, 깊이맵, 라인아트 등 추가 조건을 참고하여 이미지를 생성하도록 돕는 기능입니다. 원하는 구도나 자세를 고정할 수 있습니다."
    },
    {
      "name": "Resolution",
      "description": "출력 이미지의 해상도 크기(예: 512x512). 해상도가 높을수록 디테일이 좋아지지만 VRAM 사용량과 연산 시간이 증가합니다."
    },
    {
      "name": "Aspect Ratio",
      "description": "이미지의 가로세로 비율(예: 16:9, 4:3). 원하는 구도를 쉽게 맞출 수 있습니다."
    },
    {
      "name": "Batch Size",
      "description": "한 번에 동시에 생성하는 이미지 장수입니다. Batch Size가 크면 VRAM을 많이 소모합니다."
    },
    {
      "name": "Batch Count",
      "description": "같은 설정으로 이미지를 몇 회 반복해서 생성할지 정합니다. (예: Batch Size=2, Batch Count=3 → 총 6장 생성)"
    },
    {
      "name": "Face Restoration",
      "description": "인물의 얼굴이 일그러지거나 왜곡될 때 이를 복원하는 기능입니다. 대표적으로 GFPGAN, CodeFormer가 있습니다."
    },
    {
      "name": "Highres Fix",
      "description": "저해상도에서 먼저 그림을 생성한 후, 고해상도로 업스케일하면서 디테일을 보강하는 기능입니다. 더 깔끔하고 정밀한 결과를 얻을 수 있습니다."
    },
    {
      "name": "Dreambooth",
      "description": "Stable Diffusion 모델을 사용자가 직접 학습시켜 특정 인물이나 캐릭터를 재현하는 방법입니다. 개인화된 결과물을 얻을 수 있습니다."
    },
    {
      "name": "Textual Inversion",
      "description": "Embedding 기법의 하나로, 특정 개념을 단어 하나로 학습시켜 프롬프트에서 불러올 수 있도록 합니다."
    },
    {
      "name": "Inpainting",
      "description": "이미지의 특정 부분을 수정/교체하는 기능입니다. 마스크를 씌운 영역만 새로 생성됩니다."
    },
    {
      "name": "Outpainting",
      "description": "기존 이미지의 바깥 부분을 확장해서 새 영역을 생성하는 기능입니다. 작은 이미지를 넓게 확장할 때 유용합니다."
    },
    {
      "name": "Depth Map",
      "description": "이미지에서 거리를 표현한 지도입니다. ControlNet에서 활용하면 입체감 있는 구도와 구성을 만들 수 있습니다."
    },
    {
      "name": "Pose Estimation",
      "description": "사람의 뼈대/자세 정보를 추출하는 기능입니다. ControlNet과 함께 사용해 원하는 인물 포즈를 반영할 수 있습니다."
    },
    {
      "name": "Denoising Strength",
      "description": "img2img에서 원본 이미지를 얼마나 변경할지 정하는 값입니다. 0에 가까우면 원본 유지, 1에 가까우면 새로 생성된 이미지에 가깝습니다."
    },
    {
      "name": "Scheduler",
      "description": "샘플러와 유사하지만, 노이즈를 줄이는 과정을 시간축에 따라 다르게 조절하는 기법입니다. Diffusers 라이브러리에서 자주 사용됩니다."
    },
    {
      "name": "WAN 2.2",
      "description": "영상 생성에 사용되는 모델 가중치 버전 중 하나입니다. 특정 애니메이션 스타일이나 영상 품질을 개선하는 데 활용됩니다."
    },
    {
      "name": "Deforum",
      "description": "Stable Diffusion으로 영상을 만드는 가장 대표적인 확장 기능입니다. 카메라 이동, 줌, 회전 등을 설정해 프레임 단위로 이미지를 이어붙여 애니메이션을 만듭니다."
    },
    {
      "name": "AnimateDiff",
      "description": "영상 전용 LoRA/모델 확장으로, 캐릭터나 오브젝트가 움직이는 시퀀스를 학습한 데이터를 사용해 프레임 간 자연스러운 움직임을 만들어 줍니다."
    },
    {
      "name": "Frame Interpolation",
      "description": "두 프레임 사이에 중간 장면을 생성해 영상이 더 부드럽게 보이도록 만드는 기술입니다. FILM, RIFE 등이 대표적입니다."
    },
    {
      "name": "Temporal Consistency",
      "description": "영상 생성에서 프레임 간 일관성을 유지하는 개념입니다. 얼굴, 배경, 색감이 프레임마다 흔들리지 않게 만드는 것이 핵심입니다."
    },
    {
      "name": "Keyframe",
      "description": "Deforum 등에서 카메라 위치, 줌, 회전, 시드 등을 특정 시점에 설정하는 값입니다. 키프레임 사이를 보간해 자연스러운 움직임을 만듭니다."
    },
    {
      "name": "Interpolation",
      "description": "시드, 카메라 위치, 프롬프트 등의 값을 시작점과 끝점 사이에서 점진적으로 변하게 하는 방식입니다. 애니메이션 효과를 줄 때 핵심적으로 사용됩니다."
    },
    {
      "name": "Motion LoRA",
      "description": "움직임 데이터를 학습한 LoRA입니다. 특정 동작이나 카메라 워크를 영상에 반영할 수 있습니다."
    },
    {
      "name": "Audio2Video",
      "description": "음악이나 음성을 입력으로 받아 그 리듬이나 발화에 맞춰 영상을 생성하는 방식입니다. 예: Wav2Lip(입모양 동기화)."
    },
    {
      "name": "Video2Video",
      "description": "기존 영상을 입력으로 받아 프레임별로 변환(img2img처럼)하여 새로운 스타일의 영상으로 바꾸는 방식입니다."
    },
    {
      "name": "Text2Video",
      "description": "텍스트 프롬프트만으로 짧은 영상을 생성하는 기술입니다. Text2Video-Zero, ModelScope, Pika Labs 등이 대표적입니다."
    }
  ]
}